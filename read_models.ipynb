{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "BATCH = 8\n",
    "IMG_SIZE_e = 256\n",
    "IMG_SIZE_m = 224"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the two models with segmentationmodels framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enviroment variable\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "BACKBONE_e = 'efficientnetb3'\n",
    "preprocess_input = get_preprocessing(BACKBONE_e)\n",
    "\n",
    "# define model\n",
    "model_e = Unet(BACKBONE_e, \n",
    "             encoder_weights='imagenet', \n",
    "             classes=1, \n",
    "             input_shape=(IMG_SIZE_e, IMG_SIZE_e, 3),\n",
    "             activation='sigmoid')\n",
    "\n",
    "model_e.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5,\n",
    "                                                 beta_1=0.9, beta_2=0.999,\n",
    "                                                 epsilon=1e-7,\n",
    "                                                 amsgrad=False,\n",
    "                                                 name='Adam'), \n",
    "              loss=sm.losses.DiceLoss() + (1 * sm.losses.BinaryFocalLoss()),\n",
    "              metrics=[sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)],\n",
    "              run_eagerly=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enviroment variable\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "BACKBONE_m = 'mobilenetv2'\n",
    "preprocess_input = get_preprocessing(BACKBONE_m)\n",
    "\n",
    "# define model\n",
    "model_m = Unet(BACKBONE_m, \n",
    "             encoder_weights='imagenet', \n",
    "             classes=1, \n",
    "             input_shape=(IMG_SIZE_m, IMG_SIZE_m, 3),\n",
    "             activation='sigmoid')\n",
    "\n",
    "model_m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5,\n",
    "                                                 beta_1=0.9, beta_2=0.999,\n",
    "                                                 epsilon=1e-7,\n",
    "                                                 amsgrad=False,\n",
    "                                                 name='Adam'), \n",
    "              loss=sm.losses.DiceLoss() + (1 * sm.losses.BinaryFocalLoss()),\n",
    "              metrics=[sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)],\n",
    "              run_eagerly=False\n",
    "              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.load_weights('./models/mobilenet_deepskin_human.h5')\n",
    "model_e.load_weights('./models/efficientnet_deepskin_human.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load animal models weigts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.load_weights('./models/mobilenet_petwound_animal.h5')\n",
    "model_e.load_weights('./models/efficientnet_petwound_animal.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do whatever you want :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61e13ac39dbdc01ff270cf54475a816471153d7869cdfadde4ca04be0818d6e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
